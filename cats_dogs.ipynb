{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class Dataset(object):\n",
    "    def __getitem__(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def __len__(self):\n",
    "        raise NotImplementedError"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "train_data_path = \"./training_set/\"\n",
    "test_data_path = \"./test_set/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(train_data_path, transform=transform)\n",
    "test_data = torchvision.datasets.ImageFolder(test_data_path, transform=transform)\n",
    "\n",
    "# val_data_path = \"./val/\"\n",
    "# val_data = torchvision.datasets.ImageFolder(val_data_path, transform=transforms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "batch_size = 128\n",
    "train_data_loader = data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "test_data_loader = data.DataLoader(test_data, batch_size=batch_size)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(49152, 84)\n",
    "        self.fc2 = nn.Linear(84, 50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 49152)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "simplenet = SimpleNet()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "optimizer = optim.Adam(simplenet.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, optimizer, train_loader, epochs, device):\n",
    "    model.to(device)\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        training_loss = 0.0\n",
    "        model.train()\n",
    "\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            inputs, target = batch\n",
    "            inputs= inputs.to(device)\n",
    "            target = target.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = nn.CrossEntropyLoss()(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            training_loss += loss.data.item()\n",
    "\n",
    "        training_loss /= len(train_loader)\n",
    "\n",
    "        print(\"Epoch: {}, Training Loss: {: 2f}\".format(epoch, training_loss))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "epochs = 15\n",
    "train(simplenet, optimizer, train_data_loader, epochs, device=torch.device(\"cuda:0\"))\n",
    "\n",
    "torch.save(simplenet.state_dict(), \"./simplenet.pth\")\n",
    "\n",
    "\n",
    "# simplenet_dict = torch.load(\"./simplenet.pth\")\n",
    "# simplenet.load_state_dict(simplenet_dict)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  7%|▋         | 1/15 [00:19<04:27, 19.09s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 0, Training Loss:  1.016718\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 13%|█▎        | 2/15 [00:37<04:06, 18.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Training Loss:  0.710606\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 20%|██        | 3/15 [00:56<03:47, 18.94s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 2, Training Loss:  0.568944\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 27%|██▋       | 4/15 [01:16<03:29, 19.02s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 3, Training Loss:  0.518133\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 33%|███▎      | 5/15 [01:35<03:10, 19.01s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 4, Training Loss:  0.455660\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 40%|████      | 6/15 [01:53<02:50, 19.00s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 5, Training Loss:  0.408730\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 47%|████▋     | 7/15 [02:12<02:31, 19.00s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 6, Training Loss:  0.337036\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 53%|█████▎    | 8/15 [02:31<02:12, 18.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 7, Training Loss:  0.289686\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 60%|██████    | 9/15 [02:50<01:53, 18.99s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 8, Training Loss:  0.255157\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 67%|██████▋   | 10/15 [03:10<01:35, 19.03s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 9, Training Loss:  0.246616\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 73%|███████▎  | 11/15 [03:29<01:16, 19.03s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 10, Training Loss:  0.202283\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 80%|████████  | 12/15 [03:48<00:57, 19.05s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 11, Training Loss:  0.193396\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 87%|████████▋ | 13/15 [04:07<00:38, 19.03s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 12, Training Loss:  0.191515\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 93%|█████████▎| 14/15 [04:25<00:18, 18.97s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 13, Training Loss:  0.133549\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 15/15 [04:44<00:00, 18.99s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 14, Training Loss:  0.120633\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "from PIL import Image\n",
    "\n",
    "simplenet_dict = torch.load(\"./simplenet.pth\")\n",
    "simplenet.load_state_dict(simplenet_dict)\n",
    "\n",
    "labels = [\"cats\", \"dogs\"]\n",
    "img = Image.open(\"./cat.jpg\")\n",
    "# img = transforms(img)\n",
    "# img = img.unsqueeze(0)\n",
    "prediction = simplenet(img)\n",
    "prediction = prediction.argmax()\n",
    "\n",
    "print(labels[prediction])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "view",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-70bca6b3f2fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# img = transforms(img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# img = img.unsqueeze(0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimplenet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchbook/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-8a98ec422039>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49152\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorchbook/lib/python3.8/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    544\u001b[0m             )\n\u001b[1;32m    545\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: view"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "corrects = 0\n",
    "total = 0\n",
    "avg_list = []\n",
    "for batch in test_data_loader:\n",
    "    inputs, targets = batch\n",
    "    prediction = simplenet(inputs)\n",
    "    correct = torch.eq(torch.max(F.softmax(prediction, dim=1), dim=1)[\n",
    "                       1], targets).view(-1)\n",
    "    correct_num = torch.sum(correct)\n",
    "    total_instance = correct.size()[0]\n",
    "    corrects += correct_num.item()\n",
    "    total += total_instance\n",
    "    avg_list.append(round(corrects/total*100, 2))\n",
    "print(\"Model accuracy on test data: {}%\".format(sum(avg_list)/len(avg_list)))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model accuracy on test data: 67.409375%\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('pytorchbook': conda)"
  },
  "interpreter": {
   "hash": "483b3af1cee029246bdad20388bdc171c1cfaf5a0d4ad2b09b83b561b50fbd81"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}